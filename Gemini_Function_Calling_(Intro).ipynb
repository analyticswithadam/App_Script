{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/analyticswithadam/App_Script/blob/main/Gemini_Function_Calling_(Intro).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OxwxtvgHS6N"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNbgF29-EvrQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from google.genai.types import GenerateContentConfig, ThinkingConfig\n",
        "from google.cloud import bigquery\n",
        "\n",
        "import textwrap\n",
        "from typing import Dict\n",
        "from datetime import datetime\n",
        "import json\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "from google.colab import userdata\n",
        "cloud_project = userdata.get('Project')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_9hZ0Z2F8n8"
      },
      "outputs": [],
      "source": [
        "# Schema Function\n",
        "\n",
        "bq_client = bigquery.Client(project=cloud_project)\n",
        "table = bq_client.get_table('bigquery-public-data.austin_bikeshare.bikeshare_trips')\n",
        "schema = {}\n",
        "for field in table.schema:\n",
        "  schema[field.name] = ('Type:' +field.field_type+', Description: '+field.description)\n",
        "print(json.dumps(schema, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFnYDADBENRA"
      },
      "outputs": [],
      "source": [
        "# Schema Function AI\n",
        "\n",
        "def get_bigquery_schema(table_name: str) -> dict[str, str]:\n",
        "    \"\"\"\n",
        "    Reads the schema from a BigQuery table.\n",
        "    You should receive the full big query qualified table name if not make best guess.\n",
        "\n",
        "    Args:\n",
        "        table_name: The fully qualified table name (e.g., 'project.dataset.table').\n",
        "\n",
        "    Returns:\n",
        "        A dictionary representing the table schema.\n",
        "        fieldname:Type:Description\n",
        "\n",
        "    \"\"\"\n",
        "    bq_client = bigquery.Client(project=cloud_project)\n",
        "    table = bq_client.get_table(table_name)\n",
        "    schema = {}\n",
        "    for field in table.schema:\n",
        "        schema[field.name] = ('Type:' +field.field_type+', Description: '+field.description)\n",
        "    return schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7W4qH7HLweoX"
      },
      "outputs": [],
      "source": [
        "# Query Function\n",
        "\n",
        "bq_client = bigquery.Client(project=cloud_project)\n",
        "query = \"\"\"\n",
        "SELECT\n",
        "  EXTRACT(YEAR FROM start_time) AS year,\n",
        "  EXTRACT(QUARTER FROM start_time) AS quarter,\n",
        "  COUNT(*) AS total_trips\n",
        "FROM\n",
        "  `bigquery-public-data.austin_bikeshare.bikeshare_trips`\n",
        "WHERE EXTRACT(YEAR FROM start_time) IN (2018, 2019, 2020)\n",
        "GROUP BY\n",
        "  year, quarter\n",
        "ORDER BY\n",
        "  total_trips DESC\n",
        "\"\"\"\n",
        "query_job = bq_client.query(query)\n",
        "results = query_job.result()\n",
        "print(results.to_dataframe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjUOHwHwXt7I"
      },
      "outputs": [],
      "source": [
        "# Query Function AI\n",
        "\n",
        "def run_bigquery_query(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Executes a BigQuery SQL query and returns results as a JSON string.\n",
        "\n",
        "    Args:\n",
        "        query: The BigQuery SQL query string to execute.\n",
        "\n",
        "    Returns:\n",
        "        A JSON formatted string containing the query results. Each row is represented\n",
        "        as a dictionary, with column names as keys. Datetime objects are converted\n",
        "        to ISO 8601 formatted strings.\n",
        "    \"\"\"\n",
        "    # Big Query Code\n",
        "    bq_client = bigquery.Client(project=cloud_project)\n",
        "    query_job = bq_client.query(query)\n",
        "    results = query_job.result()\n",
        "\n",
        "    # Convert results to a list of dictionaries\n",
        "    data = []\n",
        "    for row in results:\n",
        "        row_dict = dict(row)\n",
        "        # Convert datetime objects to strings before adding to the dictionary\n",
        "        for key, value in row_dict.items():\n",
        "            if isinstance(value, datetime):\n",
        "                row_dict[key] = value.isoformat()\n",
        "        data.append(row_dict)\n",
        "\n",
        "    # Return the results as a JSON string\n",
        "    return json.dumps(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1NCKgmvEFeC"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Create a client\n",
        "client = genai.Client(\n",
        "     vertexai=True,\n",
        "     project=cloud_project,\n",
        "     location=\"us-central1\"\n",
        ")\n",
        "\n",
        "\n",
        "MODEL_ID = \"gemini-2.5-flash-preview-05-20\"\n",
        "\n",
        "sys_prompt = \"\"\"You are an expert data analyst\n",
        "    I will give you a google big query table and query instructions\n",
        "    Use the get_bigquery_schema tool to read the schema of the table and formulate the query to run.\n",
        "    Then run a query or querries using the run_bigquery_query tool to get the data to answer the users questions\n",
        "    \"\"\"\n",
        "format_prompt =\"\"\"\n",
        "    Output Format Instructions:\n",
        "\n",
        "    Please structure your response in the following four distinct sections, using the exact headings provided below.\n",
        "\n",
        "    1. Query Results\n",
        "\n",
        "    [Present the direct results of the query here in a clean, readable format (e.g., a table, a list, or a code block as appropriate).]\n",
        "\n",
        "    2. SQL Query Used\n",
        "\n",
        "    [Provide the exact SQL query or queries that were used to generate the results. Below the query, include a brief explanation of what the query does, breaking down the key clauses (SELECT, FROM, WHERE, etc.) and their purpose.]\n",
        "\n",
        "    3. Explanation\n",
        "\n",
        "    [Summarize the query results in clear, natural language. Explain what the data means and any significant patterns or conclusions that can be drawn from it.]\n",
        "\n",
        "    4. Functions Used\n",
        "\n",
        "    [List the sequence of functions or tools you used to generate this response. For each function, specify how many times it was called. For example:\n",
        "\n",
        "    Google Search: 1 time\n",
        "    code_interpreter: 2 times]\n",
        "    \"\"\"\n",
        "\n",
        "# Generate a response with function calling\n",
        "def call_llm(user_prompt):\n",
        "  output = client.models.generate_content(\n",
        "      model=MODEL_ID,\n",
        "      contents=sys_prompt +\" \"+user_prompt+\" \"+format_prompt,\n",
        "      config=types.GenerateContentConfig(\n",
        "          tools=[run_bigquery_query, get_bigquery_schema],\n",
        "          thinking_config=ThinkingConfig(include_thoughts=True)\n",
        "      ),\n",
        "  )\n",
        "  return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaIxDmHrQYpO"
      },
      "outputs": [],
      "source": [
        "# Print Response\n",
        "response = call_llm(\"\"\"Query the table bigquery-public-data.austin_bikeshare.bikeshare_trips \\\n",
        " to get the most popular season for total trips in 2018, 2019 and 2020\"\"\")\n",
        "display(Markdown(response.text))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = call_llm(\"\"\"From the table bigquery-public-data.austin_311.311_service_requests \\\n",
        " what were the most common complaint descriptions created in the last week of May 2025\"\"\")\n",
        "display(Markdown(response.text))"
      ],
      "metadata": {
        "id": "dPjHXKC15t16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOd3WzyN1-1w"
      },
      "outputs": [],
      "source": [
        "# Print Thoughts\n",
        "print(\"Thoughts:\")\n",
        "for ci, candidate in enumerate(response.candidates, start=0):\n",
        "    for part in candidate.content.parts:\n",
        "        if getattr(part, \"thought\", False):\n",
        "            wrapped = textwrap.fill(part.text, width=80)\n",
        "            print(\"\\nnew thought:\")\n",
        "            print(wrapped)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuuI95_rVY9f"
      },
      "outputs": [],
      "source": [
        "# Calculate and print individual costs\n",
        "thought_tokens = response.usage_metadata.thoughts_token_count\n",
        "thought_cost = thought_tokens * (3.50 / 1_000_000)\n",
        "\n",
        "output_tokens = response.usage_metadata.candidates_token_count\n",
        "output_cost = output_tokens * (0.60 / 1_000_000)\n",
        "\n",
        "input_tokens = response.usage_metadata.prompt_token_count\n",
        "input_cost = input_tokens * (0.15 / 1_000_000)\n",
        "\n",
        "# Print each line\n",
        "print(f\"Thought tokens: {thought_tokens}  Cost: ${thought_cost:.6f}\")\n",
        "print(f\"Output tokens: {output_tokens}  Cost: ${output_cost:.6f}\")\n",
        "print(f\"Input tokens: {input_tokens}  Cost: ${input_cost:.6f}\")\n",
        "\n",
        "# Print total cost\n",
        "total_cost = thought_cost + output_cost + input_cost\n",
        "print(f\"Total cost: ${total_cost:.6f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}